<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>Custom Loss Blocks &#8212; Apache MXNet  documentation</title>

    <link rel="stylesheet" href="../../../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mxnet.css" />
    <link rel="stylesheet" href="../../../../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/fonts.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../../_static/language_data.js"></script>
    <script type="text/javascript" src="../../../../_static/google_analytics.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="shortcut icon" href="../../../../_static/mxnet-icon.png"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="Initialization" href="../init.html" />
    <link rel="prev" title="Activation Blocks" href="../activations/activations.html" /> 
  </head>
<body><header class="site-header" role="banner">
  <div class="wrapper">
      <a class="site-title" rel="author" href="/"><img
            src="../../../../_static/mxnet_logo.png" class="site-header-logo"></a>
    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger"/>
      <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
      </label>

      <div class="trigger">
        <a class="page-link" href="/get_started">Get Started</a>
        <a class="page-link" href="/blog">Blog</a>
        <a class="page-link" href="/features">Features</a>
        <a class="page-link" href="/ecosystem">Ecosystem</a>
        <a class="page-link page-current" href="/api">Docs & Tutorials</a>
        <a class="page-link" href="https://github.com/apache/incubator-mxnet">GitHub</a>
      </div>
    </nav>
  </div>
</header>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="../../../index.html">Python Tutorials</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link" href="../../index.html">Packages</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link" href="../index.html">Gluon</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active">Custom Loss Blocks</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../../../../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../../../../_sources/tutorials/packages/gluon/custom-loss/custom-loss.ipynb" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
      </nav>
    </div>
</header><header class="mdl-layout__drawer">      
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../../index.html">Python Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../../getting-started/index.html">Getting Started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../getting-started/crash-course/index.html">Crash Course</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../getting-started/to-mxnet/index.html">Moving to MXNet from Other Frameworks</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="../../index.html">Packages</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../index.html">Gluon</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ndarray/index.html">NDArray</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../symbol/index.html">Symbol</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../autograd/autograd.html">Automatic Differentiation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../onnx/index.html">ONNX</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../performance/index.html">Performance</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../performance/compression/index.html">Compression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../performance/backend/index.html">Accelerated Backend Tools</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../deploy/index.html">Deployment</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../deploy/export/index.html">Export</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../deploy/inference/index.html">Inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../deploy/run-on-aws/index.html">Run on AWS</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../extend/index.html">Customization</a><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/index.html">Python API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/ndarray/index.html">mxnet.ndarray</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/mxnet.ndarray.NDArray.html">NDArray</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/routines.html">Routines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/mxnet.ndarray.sparse.CSRNDArray.html">CSRNDArray</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/mxnet.ndarray.sparse.RowSparseNDArray.html">RowSparseNDArray</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/sparse_routines.html">Sparse routines</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/gluon/index.html">mxnet.gluon</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/nn.html">nn and contrib.nn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/rnn.html">rnn and contrib.rnn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/mxnet.gluon.loss.html"><code class="docutils literal notranslate"><span class="pre">loss</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/mxnet.gluon.parameter.html">Parameter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/mxnet.gluon.Trainer.html">Trainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/mxnet.gluon.data.html">data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/mxnet.gluon.data.vision.html">data.vision</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/mxnet.gluon.model_zoo.html">model_zoo.vision</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/mxnet.gluon.utils.html">utils</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/gluon-related/index.html">Gluon related modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.autograd.html">mxnet.autograd</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.image.html">mxnet.image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.io.html">mxnet.io</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.recordio.html">mxnet.recordio</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.kvstore.html">mxnet.kvstore</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.optimizer.html">mxnet.optimizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.random.html">mxnet.random</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.profiler.html">mxnet.profiler</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.context.html">mxnet.context</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.initializer.html">mxnet.initializer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.lr_scheduler.html">mxnet.lr_scheduler</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.metric.html">mxnet.metric</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/symbol/index.html">mxnet.symbol</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol/mxnet.symbol.Symbol.html">Symbol</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol/mxnet.symbol.linalg.html">mxnet.linalg</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/symbol-related/index.html">Symbol related modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol-related/mxnet.callback.html">mxnet.callback</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol-related/mxnet.module.html">mxnet.module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol-related/mxnet.monitor.html">mxnet.monitor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol-related/mxnet.visualization.html">mxnet.visualization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/advanced/index.html">Advanced modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/advanced/mxnet.executor.html">mxnet.executor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/advanced/mxnet.kvstore_server.html">mxnet.kvstore_server</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/advanced/mxnet.engine.html">mxnet.engine</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/advanced/mxnet.executor_manager.html">mxnet.executor_manager</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/advanced/mxnet.rtc.html">mxnet.rtc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/advanced/mxnet.test_utils.html">mxnet.test_utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/advanced/mxnet.util.html">mxnet.util</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../../../../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">      
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../../index.html">Python Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../../getting-started/index.html">Getting Started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../getting-started/crash-course/index.html">Crash Course</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../getting-started/to-mxnet/index.html">Moving to MXNet from Other Frameworks</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="../../index.html">Packages</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../index.html">Gluon</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ndarray/index.html">NDArray</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../symbol/index.html">Symbol</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../autograd/autograd.html">Automatic Differentiation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../onnx/index.html">ONNX</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../performance/index.html">Performance</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../performance/compression/index.html">Compression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../performance/backend/index.html">Accelerated Backend Tools</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../deploy/index.html">Deployment</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../deploy/export/index.html">Export</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../deploy/inference/index.html">Inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../deploy/run-on-aws/index.html">Run on AWS</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../extend/index.html">Customization</a><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/index.html">Python API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/ndarray/index.html">mxnet.ndarray</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/mxnet.ndarray.NDArray.html">NDArray</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/routines.html">Routines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/mxnet.ndarray.sparse.CSRNDArray.html">CSRNDArray</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/mxnet.ndarray.sparse.RowSparseNDArray.html">RowSparseNDArray</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/sparse_routines.html">Sparse routines</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/gluon/index.html">mxnet.gluon</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/nn.html">nn and contrib.nn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/rnn.html">rnn and contrib.rnn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/mxnet.gluon.loss.html"><code class="docutils literal notranslate"><span class="pre">loss</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/mxnet.gluon.parameter.html">Parameter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/mxnet.gluon.Trainer.html">Trainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/mxnet.gluon.data.html">data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/mxnet.gluon.data.vision.html">data.vision</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/mxnet.gluon.model_zoo.html">model_zoo.vision</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/mxnet.gluon.utils.html">utils</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/gluon-related/index.html">Gluon related modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.autograd.html">mxnet.autograd</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.image.html">mxnet.image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.io.html">mxnet.io</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.recordio.html">mxnet.recordio</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.kvstore.html">mxnet.kvstore</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.optimizer.html">mxnet.optimizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.random.html">mxnet.random</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.profiler.html">mxnet.profiler</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.context.html">mxnet.context</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.initializer.html">mxnet.initializer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.lr_scheduler.html">mxnet.lr_scheduler</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon-related/mxnet.metric.html">mxnet.metric</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/symbol/index.html">mxnet.symbol</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol/mxnet.symbol.Symbol.html">Symbol</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol/mxnet.symbol.linalg.html">mxnet.linalg</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/symbol-related/index.html">Symbol related modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol-related/mxnet.callback.html">mxnet.callback</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol-related/mxnet.module.html">mxnet.module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol-related/mxnet.monitor.html">mxnet.monitor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol-related/mxnet.visualization.html">mxnet.visualization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/advanced/index.html">Advanced modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/advanced/mxnet.executor.html">mxnet.executor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/advanced/mxnet.kvstore_server.html">mxnet.kvstore_server</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/advanced/mxnet.engine.html">mxnet.engine</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/advanced/mxnet.executor_manager.html">mxnet.executor_manager</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/advanced/mxnet.rtc.html">mxnet.rtc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/advanced/mxnet.test_utils.html">mxnet.test_utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/advanced/mxnet.util.html">mxnet.util</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content">
        
  <div class="section" id="Custom-Loss-Blocks">
<h1>Custom Loss Blocks<a class="headerlink" href="#Custom-Loss-Blocks" title="Permalink to this headline">¶</a></h1>
<p>All neural networks need a loss function for training. A loss function is a quantative measure of how bad the predictions of the network are when compared to ground truth labels. Given this score, a network can improve by iteratively updating its weights to minimise this loss. Some tasks use a combination of multiple loss functions, but often you’ll just use one. MXNet Gluon provides a number of the most commonly used loss functions, and you’ll choose certain functions depending on your network
and task. Some common task and loss function pairs include:</p>
<ul class="simple">
<li><p>Regression: <a class="reference external" href="https://beta.mxnet.io/api/gluon/_autogen/mxnet.gluon.loss.L1Loss.html">L1Loss</a>, <a class="reference external" href="https://beta.mxnet.io/api/gluon/_autogen/mxnet.gluon.loss.L2Loss.html">L2Loss</a></p></li>
<li><p>Classification: <a class="reference external" href="https://beta.mxnet.io/api/gluon/_autogen/mxnet.gluon.loss.SigmoidBinaryCrossEntropyLoss.html">SigmoidBinaryCrossEntropyLoss</a>, <a class="reference external" href="https://beta.mxnet.io/api/gluon/_autogen/mxnet.gluon.loss.SoftmaxBinaryCrossEntropyLoss.html">SoftmaxBinaryCrossEntropyLoss</a></p></li>
<li><p>Embeddings: <a class="reference external" href="https://beta.mxnet.io/api/gluon/_autogen/mxnet.gluon.loss.HingeLoss.html">HingeLoss</a></p></li>
</ul>
<p>However, we may sometimes want to solve problems that require customized loss functions; this tutorial shows how we can do that in Gluon. We will implement contrastive loss which is typically used in Siamese networks.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">mxnet</span> <span class="kn">as</span> <span class="nn">mx</span>
<span class="kn">from</span> <span class="nn">mxnet</span> <span class="kn">import</span> <span class="n">autograd</span><span class="p">,</span> <span class="n">gluon</span><span class="p">,</span> <span class="n">nd</span>
<span class="kn">from</span> <span class="nn">mxnet.gluon.loss</span> <span class="kn">import</span> <span class="n">Loss</span>
<span class="kn">import</span> <span class="nn">random</span>
</pre></div>
</div>
<div class="section" id="What-is-Contrastive-Loss">
<h2>What is Contrastive Loss<a class="headerlink" href="#What-is-Contrastive-Loss" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf">Contrastive loss</a> is a distance-based loss function. During training, pairs of images are fed into a model. If the images are similar, the loss function will return 0, otherwise 1.</p>
<p><em>Y</em> is a binary label indicating similarity between training images. Contrastive loss uses the Euclidean distance <em>D</em> between images and is the sum of 2 terms: - the loss for a pair of similar points - the loss for a pair of dissimilar points</p>
<p>The loss function uses a margin <em>m</em> which is has the effect that dissimlar pairs only contribute if their loss is within a certain margin.</p>
<p>In order to implement such a customized loss function in Gluon, we only need to define a new class that is inheriting from the <code class="docutils literal notranslate"><span class="pre">`Loss</span></code> &lt;<a class="reference external" href="https://mxnet.incubator.apache.org/api/python/gluon/loss.html#mxnet.gluon.loss.Loss">https://mxnet.incubator.apache.org/api/python/gluon/loss.html#mxnet.gluon.loss.Loss</a>&gt;`__ base class. We then define the contrastive loss logic in the <code class="docutils literal notranslate"><span class="pre">`hybrid_forward</span></code> &lt;<a class="reference external" href="http://mxnet.apache.org/_modules/mxnet/gluon/block.html#HybridBlock.hybrid_forward">http://mxnet.apache.org/_modules/mxnet/gluon/block.html#HybridBlock.hybrid_forward</a>&gt;`__ method. This method takes the images <code class="docutils literal notranslate"><span class="pre">image1</span></code>, <code class="docutils literal notranslate"><span class="pre">image2</span></code> and the label which defines whether
<code class="docutils literal notranslate"><span class="pre">image1</span></code> and <code class="docutils literal notranslate"><span class="pre">image2</span></code> are similar (=0) or dissimilar (=1). The input F is an <code class="docutils literal notranslate"><span class="pre">mxnet.ndarry</span></code> or an <code class="docutils literal notranslate"><span class="pre">mxnet.symbol</span></code> if we hybridize the network. Gluon’s <code class="docutils literal notranslate"><span class="pre">Loss</span></code> base class is in fact a <code class="docutils literal notranslate"><span class="pre">`HybridBlock</span></code> &lt;<a class="reference external" href="http://mxnet.apache.org/api/python/gluon/gluon.html#mxnet.gluon.HybridBlock">http://mxnet.apache.org/api/python/gluon/gluon.html#mxnet.gluon.HybridBlock</a>&gt;`__. This means we can either run imperatively or symbolically. When we hybridize our custom loss function, we can get performance speedups.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ContrastiveLoss</span><span class="p">(</span><span class="n">Loss</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mf">6.</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">batch_axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ContrastiveLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">batch_axis</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">margin</span> <span class="o">=</span> <span class="n">margin</span>

    <span class="k">def</span> <span class="nf">hybrid_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">image1</span><span class="p">,</span> <span class="n">image2</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="n">distances</span> <span class="o">=</span> <span class="n">image1</span> <span class="o">-</span> <span class="n">image2</span>
        <span class="n">distances_squared</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">distances</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">euclidean_distances</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">distances_squared</span> <span class="o">+</span> <span class="mf">0.0001</span><span class="p">)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">margin</span> <span class="o">-</span> <span class="n">euclidean_distances</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">margin</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">label</span><span class="p">)</span> <span class="o">*</span> <span class="n">distances_squared</span> <span class="o">+</span> <span class="n">label</span> <span class="o">*</span> <span class="n">F</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">loss</span>
        <span class="k">return</span> <span class="n">loss</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">ContrastiveLoss</span><span class="p">(</span><span class="n">margin</span><span class="o">=</span><span class="mf">6.0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="Define-the-Siamese-network">
<h2>Define the Siamese network<a class="headerlink" href="#Define-the-Siamese-network" title="Permalink to this headline">¶</a></h2>
<p>A <a class="reference external" href="https://papers.nips.cc/paper/769-signature-verification-using-a-siamese-time-delay-neural-network.pdf">Siamese network</a> consists of 2 identical networks, that share the same weights. They are trained on pairs of images and each network processes one image. The label defines whether the pair of images is similar or not. The Siamese network learns to differentiate between two input images.</p>
<p>Our network consists of 2 convolutional and max pooling layers that downsample the input image. The output is then fed through a fully connected layer with 256 hidden units and another fully connected layer with 2 hidden units.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Siamese</span><span class="p">(</span><span class="n">gluon</span><span class="o">.</span><span class="n">HybridBlock</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Siamese</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">name_scope</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cnn</span> <span class="o">=</span> <span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">HybridSequential</span><span class="p">()</span>
            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">cnn</span><span class="o">.</span><span class="n">name_scope</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cnn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cnn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2D</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cnn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cnn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2D</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cnn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cnn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softrelu&#39;</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">hybrid_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">input0</span><span class="p">,</span> <span class="n">input1</span><span class="p">):</span>
        <span class="n">out0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cnn</span><span class="p">(</span><span class="n">input0</span><span class="p">)</span>
        <span class="n">out1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cnn</span><span class="p">(</span><span class="n">input1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out0</span><span class="p">,</span> <span class="n">out1</span>
</pre></div>
</div>
</div>
<div class="section" id="Prepare-the-training-data">
<h2>Prepare the training data<a class="headerlink" href="#Prepare-the-training-data" title="Permalink to this headline">¶</a></h2>
<p>We train our network on the <a class="reference external" href="http://www.omniglot.com/">Ominglot</a> dataset which is a collection of 1623 hand drawn characters from 50 alphabets. You can download it from <a class="reference external" href="https://github.com/brendenlake/omniglot/tree/master/python">here</a>. We need to create a dataset that contains a random set of similar and dissimilar images. We use Gluon’s <code class="docutils literal notranslate"><span class="pre">ImageFolderDataset</span></code> where we overwrite <code class="docutils literal notranslate"><span class="pre">__getitem__</span></code> and randomly return similar and dissimilar pairs of images.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GetImagePairs</span><span class="p">(</span><span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">vision</span><span class="o">.</span><span class="n">ImageFolderDataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">root</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GetImagePairs</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">flag</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">=</span> <span class="n">root</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="n">items_with_index</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">))</span>
        <span class="n">image0_index</span><span class="p">,</span> <span class="n">image0_tuple</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">items_with_index</span><span class="p">)</span>
        <span class="n">should_get_same_class</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">should_get_same_class</span><span class="p">:</span>
            <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
                <span class="n">image1_index</span><span class="p">,</span> <span class="n">image1_tuple</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">items_with_index</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">image0_tuple</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">image1_tuple</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
                    <span class="k">break</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">image1_index</span><span class="p">,</span> <span class="n">image1_tuple</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">items_with_index</span><span class="p">)</span>
        <span class="n">image0</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="n">image0_index</span><span class="p">)</span>
        <span class="n">image1</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="n">image1_index</span><span class="p">)</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">image1_tuple</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">image0_tuple</span><span class="p">[</span><span class="mi">1</span><span class="p">])])</span>
        <span class="k">return</span> <span class="n">image0</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">image1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__len__</span><span class="p">()</span>
</pre></div>
</div>
<p>We train the network on a subset of the data, the <a class="reference external" href="https://www.omniglot.com/writing/tifinagh.htm">Tifinagh</a> alphabet. Once the model is trained we test it on the <a class="reference external" href="https://www.omniglot.com/writing/inuktitut.htm">Inuktitut</a> alphabet.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">img0</span><span class="p">,</span> <span class="n">img1</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
    <span class="n">normalized_img0</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">img0</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">/</span><span class="mf">255.0</span>
    <span class="n">normalized_img1</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">img1</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">/</span><span class="mf">255.0</span>
    <span class="k">return</span> <span class="n">normalized_img0</span><span class="p">,</span> <span class="n">normalized_img1</span><span class="p">,</span> <span class="n">label</span>

<span class="n">training_dir</span> <span class="o">=</span> <span class="s2">&quot;images_background/Tifinagh&quot;</span>
<span class="n">testing_dir</span> <span class="o">=</span> <span class="s2">&quot;images_background/Inuktitut_(Canadian_Aboriginal_Syllabics)&quot;</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">GetImagePairs</span><span class="p">(</span><span class="n">training_dir</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">GetImagePairs</span><span class="p">(</span><span class="n">testing_dir</span><span class="p">)</span>
<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">gluon</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">transform</span><span class="p">),</span>
                                        <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">gluon</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">transform</span><span class="p">),</span>
                                        <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Following code plots some examples from the test dataset.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">img1</span><span class="p">,</span> <span class="n">img2</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Same: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">label</span><span class="o">.</span><span class="n">asscalar</span><span class="p">())</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>
<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax0</span><span class="p">,</span> <span class="n">ax1</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax0</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img1</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()[:,:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">ax0</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img2</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()[:,:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p><img alt="example1" src="tutorials/packages/gluon/custom-loss/images/inuktitut_1.png" /></p>
</div>
<div class="section" id="Train-the-Siamese-network">
<h2>Train the Siamese network<a class="headerlink" href="#Train-the-Siamese-network" title="Permalink to this headline">¶</a></h2>
<p>Before we can start training, we need to instantiate the custom constrastive loss function and initialize the model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Siamese</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="n">init</span><span class="o">=</span><span class="n">mx</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">Xavier</span><span class="p">())</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">gluon</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(),</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">})</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">ContrastiveLoss</span><span class="p">(</span><span class="n">margin</span><span class="o">=</span><span class="mf">6.0</span><span class="p">)</span>
</pre></div>
</div>
<p>Start the training loop:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">):</span>
        <span class="n">image1</span><span class="p">,</span> <span class="n">image2</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">data</span>
        <span class="k">with</span> <span class="n">autograd</span><span class="o">.</span><span class="n">record</span><span class="p">():</span>
            <span class="n">output1</span><span class="p">,</span> <span class="n">output2</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">image1</span><span class="p">,</span> <span class="n">image2</span><span class="p">)</span>
            <span class="n">loss_contrastive</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">output1</span><span class="p">,</span> <span class="n">output2</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="n">loss_contrastive</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">trainer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">image1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">loss_mean</span> <span class="o">=</span> <span class="n">loss_contrastive</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">asscalar</span><span class="p">()</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Epoch number {}</span><span class="se">\n</span><span class="s2"> Current loss {}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">loss_mean</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="Test-the-trained-Siamese-network">
<h2>Test the trained Siamese network<a class="headerlink" href="#Test-the-trained-Siamese-network" title="Permalink to this headline">¶</a></h2>
<p>During inference we compute the Euclidean distance between the output vectors of the Siamese network. High distance indicates dissimilarity, low values indicate similarity.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">):</span>
    <span class="n">img1</span><span class="p">,</span> <span class="n">img2</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">output1</span><span class="p">,</span> <span class="n">output2</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">img1</span><span class="p">,</span> <span class="n">img2</span><span class="p">)</span>
    <span class="n">dist_sq</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">ndarray</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mx</span><span class="o">.</span><span class="n">ndarray</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">output1</span> <span class="o">-</span> <span class="n">output2</span><span class="p">))</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">ndarray</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dist_sq</span><span class="p">)</span><span class="o">.</span><span class="n">asscalar</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Euclidean Distance:&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="p">,</span> <span class="s2">&quot;Test label&quot;</span><span class="p">,</span> <span class="n">label</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">asscalar</span><span class="p">())</span>
    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax0</span><span class="p">,</span> <span class="n">ax1</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">ax0</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img1</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="n">ax0</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img2</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p><img alt="example2" src="tutorials/packages/gluon/custom-loss/images/inuktitut_2.png" /></p>
</div>
<div class="section" id="Common-pitfalls-with-custom-loss-functions">
<h2>Common pitfalls with custom loss functions<a class="headerlink" href="#Common-pitfalls-with-custom-loss-functions" title="Permalink to this headline">¶</a></h2>
<p>When customizing loss functions, we may encounter certain pitfalls. If the loss is not decreasing as expected or if forward/backward pass is crashing, then one should check the following:</p>
<div class="section" id="Activation-function-in-the-last-layer">
<h3>Activation function in the last layer<a class="headerlink" href="#Activation-function-in-the-last-layer" title="Permalink to this headline">¶</a></h3>
<p>Verify whether the last network layer uses the correct activation function: for instance in binary classification tasks we need to apply a sigmoid on the output data. If we use this activation in the last layer and define a loss function like Gluon’s SigmoidBinaryCrossEntropy, we would basically apply sigmoid twice and the loss would not converge as expected. If we don’t define any activation function, Gluon will per default apply a linear activation.</p>
</div>
<div class="section" id="Intermediate-loss-values">
<h3>Intermediate loss values<a class="headerlink" href="#Intermediate-loss-values" title="Permalink to this headline">¶</a></h3>
<p>In our example, we computed the square root of squared distances between 2 images: <code class="docutils literal notranslate"><span class="pre">F.sqrt(distances_squared)</span></code>. If images are very similar we take the sqare root of a value close to 0, which can lead to <em>NaN</em> values. Adding a small epsilon to <code class="docutils literal notranslate"><span class="pre">distances_squared</span></code> avoids this problem.</p>
</div>
<div class="section" id="Shape-of-intermediate-loss-vectors">
<h3>Shape of intermediate loss vectors<a class="headerlink" href="#Shape-of-intermediate-loss-vectors" title="Permalink to this headline">¶</a></h3>
<p>In most cases having the wrong tensor shape will lead to an error, as soon as we compare data with labels. But in some cases, we may be able to normally run the training, but it does not converge. For instance, if we don’t set <code class="docutils literal notranslate"><span class="pre">keepdims=True</span></code> in our customized loss function, the shape of the tensor changes. The example still runs fine but does not converge.</p>
<p>If you encounter a similar problem, then it is useful to check the tensor shape after each computation step in the loss function.</p>
</div>
<div class="section" id="Differentiable">
<h3>Differentiable<a class="headerlink" href="#Differentiable" title="Permalink to this headline">¶</a></h3>
<p>Backprogration requires the loss function to be differentiable. If the customized loss function cannot be differentiated the backward pass will crash.</p>
</div>
</div>
</div>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">Custom Loss Blocks</a><ul>
<li><a class="reference internal" href="#What-is-Contrastive-Loss">What is Contrastive Loss</a></li>
<li><a class="reference internal" href="#Define-the-Siamese-network">Define the Siamese network</a></li>
<li><a class="reference internal" href="#Prepare-the-training-data">Prepare the training data</a></li>
<li><a class="reference internal" href="#Train-the-Siamese-network">Train the Siamese network</a></li>
<li><a class="reference internal" href="#Test-the-trained-Siamese-network">Test the trained Siamese network</a></li>
<li><a class="reference internal" href="#Common-pitfalls-with-custom-loss-functions">Common pitfalls with custom loss functions</a><ul>
<li><a class="reference internal" href="#Activation-function-in-the-last-layer">Activation function in the last layer</a></li>
<li><a class="reference internal" href="#Intermediate-loss-values">Intermediate loss values</a></li>
<li><a class="reference internal" href="#Shape-of-intermediate-loss-vectors">Shape of intermediate loss vectors</a></li>
<li><a class="reference internal" href="#Differentiable">Differentiable</a></li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>                    

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="../activations/activations.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>Activation Blocks</div>
         </div>
     </a>
     <a id="button-next" href="../init.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>Initialization</div>
        </div>
     </a>
  </div>
            <footer class="site-footer h-card">
    <div class="wrapper">
        <div class="row">
            <div class="col-4">
                <h4 class="footer-category-title">Resources</h4>
                <ul class="contact-list">
                    <li><a class="u-email" href="mailto:dev@mxnet.apache.org">Dev list</a></li>
                    <li><a class="u-email" href="mailto:user@mxnet.apache.org">User mailing list</a></li>
                    <li><a href="https://cwiki.apache.org/confluence/display/MXNET/Apache+MXNet+Home">Developer Wiki</a></li>
                    <li><a href="https://issues.apache.org/jira/projects/MXNET/issues">Jira Tracker</a></li>
                    <li><a href="https://github.com/apache/incubator-mxnet/labels/Roadmap">Github Roadmap</a></li>
                    <li><a href="https://discuss.mxnet.io">MXNet Discuss forum</a></li>
                    <li><a href="/mxnet.io-v2/community/contribute">Contribute To MXNet</a></li>

                </ul>
            </div>

            <div class="col-4"><ul class="social-media-list"><li><a href="https://github.com/apache/incubator-mxnet"><svg class="svg-icon"><use xlink:href="../../../../_static/minima-social-icons.svg#github"></use></svg> <span class="username">apache/incubator-mxnet</span></a></li><li><a href="https://www.twitter.com/apachemxnet"><svg class="svg-icon"><use xlink:href="../../../../_static/minima-social-icons.svg#twitter"></use></svg> <span class="username">apachemxnet</span></a></li><li><a href="https://youtube.com/apachemxnet"><svg class="svg-icon"><use xlink:href="../../../../_static/minima-social-icons.svg#youtube"></use></svg> <span class="username">apachemxnet</span></a></li></ul>
</div>

            <div class="col-4 footer-text">
                <p>A flexible and efficient library for deep learning.</p>
            </div>
        </div>
    </div>
</footer>

<footer class="site-footer2">
    <div class="wrapper">
        <div class="row">
            <div class="col-3">
                <img src="../../../../_static/apache_incubator_logo.png" class="footer-logo col-2">
            </div>
            <div class="footer-bottom-warning col-9">
                <p>Apache MXNet is an effort undergoing incubation at The Apache Software Foundation (ASF), <span style="font-weight:bold">sponsored by the <i>Apache Incubator</i></span>. Incubation is required
                    of all newly accepted projects until a further review indicates that the infrastructure,
                    communications, and decision making process have stabilized in a manner consistent with other
                    successful ASF projects. While incubation status is not necessarily a reflection of the completeness
                    or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.
                </p><p>"Copyright © 2017-2018, The Apache Software Foundation Apache MXNet, MXNet, Apache, the Apache
                    feather, and the Apache MXNet project logo are either registered trademarks or trademarks of the
                    Apache Software Foundation."</p>
            </div>
        </div>
    </div>
</footer>
        
  </body>
</html>